{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия FP_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSVSzNNR1dwN",
        "colab_type": "code",
        "outputId": "2a453ae9-25fb-4758-bef3-c39cd621d320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import time\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "class DRCN(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super(DRCN, self).__init__()\n",
        "\n",
        "        # convolutional encoder\n",
        "\n",
        "        self.enc_feat = nn.Sequential()\n",
        "        self.enc_feat.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=100, kernel_size=5,\n",
        "                                                    padding=2))\n",
        "        self.enc_feat.add_module('relu1', nn.ReLU(True))\n",
        "        self.enc_feat.add_module('pool1', nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.enc_feat.add_module('conv2', nn.Conv2d(in_channels=100, out_channels=150, kernel_size=5,\n",
        "                                                    padding=2))\n",
        "        self.enc_feat.add_module('relu2', nn.ReLU(True))\n",
        "        self.enc_feat.add_module('pool2', nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.enc_feat.add_module('conv3', nn.Conv2d(in_channels=150, out_channels=200, kernel_size=3,\n",
        "                                                    padding=1))\n",
        "        self.enc_feat.add_module('relu3', nn.ReLU(True))\n",
        "\n",
        "        self.enc_dense = nn.Sequential()\n",
        "        self.enc_dense.add_module('fc4', nn.Linear(in_features=200 * 8 * 8, out_features=1024))\n",
        "        self.enc_dense.add_module('relu4', nn.ReLU(True))\n",
        "        self.enc_dense.add_module('drop4', nn.Dropout2d())\n",
        "\n",
        "        self.enc_dense.add_module('fc5', nn.Linear(in_features=1024, out_features=1024))\n",
        "        self.enc_dense.add_module('relu5', nn.ReLU(True))\n",
        "\n",
        "        # label predict layer\n",
        "        self.pred = nn.Sequential()\n",
        "        self.pred.add_module('dropout6', nn.Dropout2d())\n",
        "        self.pred.add_module('predict6', nn.Linear(in_features=1024, out_features=n_class))\n",
        "\n",
        "        # convolutional decoder\n",
        "\n",
        "        self.rec_dense = nn.Sequential()\n",
        "        self.rec_dense.add_module('fc5_', nn.Linear(in_features=1024, out_features=1024))\n",
        "        self.rec_dense.add_module('relu5_', nn.ReLU(True))\n",
        "\n",
        "        self.rec_dense.add_module('fc4_', nn.Linear(in_features=1024, out_features=200 * 8 * 8))\n",
        "        self.rec_dense.add_module('relu4_', nn.ReLU(True))\n",
        "\n",
        "        self.rec_feat = nn.Sequential()\n",
        "\n",
        "        self.rec_feat.add_module('conv3_', nn.Conv2d(in_channels=200, out_channels=150,\n",
        "                                                     kernel_size=3, padding=1))\n",
        "        self.rec_feat.add_module('relu3_', nn.ReLU(True))\n",
        "        self.rec_feat.add_module('pool3_', nn.Upsample(scale_factor=2))\n",
        "\n",
        "        self.rec_feat.add_module('conv2_', nn.Conv2d(in_channels=150, out_channels=100,\n",
        "                                                     kernel_size=5, padding=2))\n",
        "        self.rec_feat.add_module('relu2_', nn.ReLU(True))\n",
        "        self.rec_feat.add_module('pool2_', nn.Upsample(scale_factor=2))\n",
        "\n",
        "        self.rec_feat.add_module('conv1_', nn.Conv2d(in_channels=100, out_channels=1,\n",
        "                                                     kernel_size=5, padding=2))\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        feat = self.enc_feat(input_data)\n",
        "        feat = feat.view(-1, 200 * 8 * 8)\n",
        "        feat_code = self.enc_dense(feat)\n",
        "\n",
        "        pred_label = self.pred(feat_code)\n",
        "\n",
        "        feat_encode = self.rec_dense(feat_code)\n",
        "        feat_encode = feat_encode.view(-1, 200, 8, 8)\n",
        "        img_rec = self.rec_feat(feat_encode)\n",
        "\n",
        "        return pred_label, img_rec, feat_code"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41fHeHAC1vi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test on the MNIST test dataset\n",
        "def test(epoch):\n",
        "\n",
        "    model_root = '/content/gdrive/My Drive'\n",
        "    image_root = os.path.join('/content/gdrive/My Drive/dataset', 'mnist')\n",
        "\n",
        "    cuda = True\n",
        "    cudnn.benchmark = True\n",
        "    batch_size = 64\n",
        "    image_size = 32\n",
        "\n",
        "    # load data\n",
        "    img_transform = transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.MNIST(\n",
        "        root=image_root,\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=img_transform\n",
        "    )\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=8\n",
        "    )\n",
        "\n",
        "    # test\n",
        "    my_net = torch.load(os.path.join(\n",
        "        model_root, 'svhn_mnist_model_epoch_' + str(epoch) + '.pth')\n",
        "    )\n",
        "\n",
        "    my_net = my_net.eval()\n",
        "    if cuda:\n",
        "        my_net = my_net.cuda()\n",
        "\n",
        "    len_dataloader = len(data_loader)\n",
        "    data_iter = iter(data_loader)\n",
        "\n",
        "    i = 0\n",
        "    n_total = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "\n",
        "        data = data_iter.next()\n",
        "        img, label = data\n",
        "\n",
        "        batch_size = len(label)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 1, image_size, image_size)\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "\n",
        "        if cuda:\n",
        "            img = img.cuda()\n",
        "            label = label.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "            class_label = class_label.cuda()\n",
        "\n",
        "        input_img.resize_as_(img).copy_(img)\n",
        "        class_label.resize_as_(label).copy_(label)\n",
        "        inputv_img = Variable(input_img)\n",
        "        classv_label = Variable(class_label)\n",
        "\n",
        "        pred_label, _, _ = my_net(input_data=inputv_img)\n",
        "        pred = pred_label.data.max(1, keepdim=True)[1]\n",
        "        n_correct += pred.eq(classv_label.data.view_as(pred)).cpu().sum()\n",
        "        n_total += batch_size\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    accu = n_correct * 1.0 / n_total\n",
        "\n",
        "    print ('epoch: %d, mnist test accuracy: %f' %(epoch, accu))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jos83YRc14yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test on the SVHN test dataset\n",
        "def rec_image(epoch):\n",
        "\n",
        "    model_root = '/content/gdrive/My Drive'\n",
        "    image_root = os.path.join('/content/gdrive/My Drive/dataset', 'svhn')\n",
        "\n",
        "    cuda = True\n",
        "    cudnn.benchmark = True\n",
        "    batch_size = 64\n",
        "    image_size = 32\n",
        "\n",
        "    # load data\n",
        "    img_transfrom = transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.Grayscale(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.SVHN(\n",
        "        root=image_root,\n",
        "        split='test',\n",
        "        download=True,\n",
        "        transform=img_transfrom\n",
        "    )\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=8\n",
        "    )\n",
        "\n",
        "    # test\n",
        "    my_net = torch.load(os.path.join(\n",
        "        model_root, 'svhn_mnist_model_epoch_' + str(epoch) + '.pth')\n",
        "    )\n",
        "    i = 0\n",
        "    n_total = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    my_net = my_net.eval()\n",
        "    if cuda:\n",
        "        my_net = my_net.cuda()\n",
        "\n",
        "    data_iter = iter(data_loader)\n",
        "    data = data_iter.next()\n",
        "    img, label = data\n",
        "    batch_size = len(img)\n",
        "\n",
        "    input_img = torch.FloatTensor(batch_size, 1, image_size, image_size)\n",
        "    class_label = torch.LongTensor(batch_size)\n",
        "\n",
        "    if cuda:\n",
        "        img = img.cuda()\n",
        "        label = label.cuda()\n",
        "        input_img = input_img.cuda()\n",
        "        class_label = class_label.cuda()\n",
        "\n",
        "    input_img.resize_as_(img).copy_(img)\n",
        "    inputv_img = Variable(input_img)\n",
        "    class_label.resize_as_(label).copy_(label)\n",
        "    classv_label = Variable(class_label)\n",
        "\n",
        "    pred_label, rec_img, _ = my_net(input_data=inputv_img)\n",
        "    pred = pred_label.data.max(1, keepdim=True)[1]\n",
        "    n_correct += pred.eq(classv_label.data.view_as(pred)).cpu().sum()\n",
        "    n_total += batch_size\n",
        "\n",
        "    accu = n_correct * 1.0 / n_total\n",
        "    print ('epoch: %d, svhn test accuracy: %f' %(epoch, accu))\n",
        "\n",
        "    # vutils.save_image(input_img, '/content/gdrive/My Drive/svhn_real_epoch_' + str(epoch) + '.png', nrow=8)\n",
        "    # vutils.save_image(rec_img.data, '/content/gdrive/My Drive/svhn_rec_' + str(epoch) + '.png', nrow=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "982wK8nU1gHR",
        "colab_type": "code",
        "outputId": "d8af842d-73de-492f-fb9d-1eb79a86edbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "source_dataset_name = 'SVHN'\n",
        "target_dataset_name = 'mnist'\n",
        "source_dataset = os.path.join('/content/gdrive/My Drive/dataset', 'svhn')\n",
        "target_dataset = os.path.join('/content/gdrive/My Drive/dataset', 'mnist')\n",
        "model_root = '/content/gdrive/My Drive'   # directory to save trained models\n",
        "cuda = True\n",
        "cudnn.benchmark = True\n",
        "lr = 1e-4\n",
        "batch_size = 64\n",
        "image_size = 32\n",
        "n_epoch = 20\n",
        "weight_decay = 5e-6\n",
        "m_lambda = 0.7\n",
        "\n",
        "# weights initialisation with Xavier Uniform initializer\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.xavier_uniform(m.weight.data, gain=1)\n",
        "        nn.init.constant(m.bias.data, 0.1)\n",
        "\n",
        "manual_seed = random.randint(1, 10000)\n",
        "random.seed(manual_seed)\n",
        "torch.manual_seed(manual_seed)\n",
        "\n",
        "# load data\n",
        "img_transform_svhn = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "img_transform_mnist = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset_source = datasets.SVHN(\n",
        "    root=source_dataset,\n",
        "    split='train',\n",
        "    download=True,\n",
        "    transform=img_transform_svhn,\n",
        ")\n",
        "\n",
        "datasetloader_source = torch.utils.data.DataLoader(\n",
        "    dataset=dataset_source,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=8\n",
        ")\n",
        "\n",
        "dataset_target = datasets.MNIST(\n",
        "    root=target_dataset,\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=img_transform_mnist,\n",
        ")\n",
        "\n",
        "datasetloader_target = torch.utils.data.DataLoader(\n",
        "    dataset=dataset_target,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=8\n",
        ")\n",
        "\n",
        "# load model\n",
        "my_net = DRCN(n_class=10)\n",
        "my_net.apply(weights_init)\n",
        "\n",
        "# setup Adam optimizer\n",
        "optimizer_classify = optim.Adam([{'params': my_net.enc_feat.parameters()},\n",
        "                                    {'params': my_net.enc_dense.parameters()},\n",
        "                                    {'params': my_net.pred.parameters()}], lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "optimizer_rec = optim.Adam([{'params': my_net.enc_feat.parameters()},\n",
        "                               {'params': my_net.enc_dense.parameters()},\n",
        "                               {'params': my_net.rec_dense.parameters()},\n",
        "                               {'params': my_net.rec_feat.parameters()}], lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "loss_class = nn.CrossEntropyLoss()\n",
        "loss_rec = nn.MSELoss()\n",
        "\n",
        "if cuda:\n",
        "    my_net = my_net.cuda()\n",
        "    loss_class = loss_class.cuda()\n",
        "    loss_rec = loss_rec.cuda()\n",
        "\n",
        "for p in my_net.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "len_source = len(datasetloader_source)\n",
        "len_target = len(datasetloader_target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/train_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzgFnqbyJUki",
        "colab_type": "code",
        "outputId": "3bda25c1-4b91-454f-b758-a8378933cf14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# training\n",
        "for epoch in range(n_epoch):\n",
        "\n",
        "    # train a convolutional autoencoder for target data reconstruction\n",
        "    dataset_target_iter = iter(datasetloader_target)\n",
        "\n",
        "    i = 0\n",
        "    n_total = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    while i < len_target:\n",
        "        my_net.zero_grad()\n",
        "\n",
        "        data_target = dataset_target_iter.next()\n",
        "        t_img, _ = data_target\n",
        "\n",
        "        batch_size = len(t_img)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 1, image_size, image_size)\n",
        "\n",
        "        if cuda:\n",
        "            t_img = t_img.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "\n",
        "        input_img.resize_as_(t_img).copy_(t_img)\n",
        "        inputv_img = Variable(input_img)\n",
        "\n",
        "        _, rec_img, latent_img = my_net(input_data=inputv_img)\n",
        "        # save_image(rec_img.data, './recovery_image/mnist_rec' + str(epoch) + '.png', nrow=8)\n",
        "\n",
        "        rec_img = rec_img.view(-1, 1 * image_size * image_size)\n",
        "        inputv_img_img = inputv_img.contiguous().view(-1, 1 * image_size * image_size)\n",
        "        shape = list(rec_img.size())\n",
        "        inputv_img = inputv_img.resize(shape[0], 1024)\n",
        "        err_rec = (1 - m_lambda) * loss_rec(rec_img, inputv_img)\n",
        "        err_rec.backward()\n",
        "        optimizer_rec.step()\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    # print ('epoch: %d, err_rec %f' \\\n",
        "    #       % (epoch, err_rec.cpu().data.numpy()))\n",
        "\n",
        "    # train a convolutional network for label prediction based on the source data\n",
        "\n",
        "    dataset_source_iter = iter(datasetloader_source)\n",
        "\n",
        "    i = 0\n",
        "    latent_img_list = []\n",
        "\n",
        "    while i < len_source:\n",
        "        my_net.zero_grad()\n",
        "\n",
        "        data_source = dataset_source_iter.next()\n",
        "        s_img, s_label = data_source\n",
        "        s_label = s_label.long().squeeze()\n",
        "\n",
        "        batch_size = len(s_label)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 1, image_size, image_size)\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "        if cuda:\n",
        "            s_img = s_img.cuda()\n",
        "            s_label = s_label.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "            class_label = class_label.cuda()\n",
        "\n",
        "\n",
        "        input_img.resize_as_(s_img).copy_(s_img)\n",
        "        class_label.resize_as_(s_label).copy_(s_label)\n",
        "        inputv_img = Variable(input_img)\n",
        "        classv_label = Variable(class_label)\n",
        "\n",
        "        pred_label, _, latent_img = my_net(input_data=inputv_img)\n",
        "        err_class = m_lambda * loss_class(pred_label, classv_label)\n",
        "        err_class.backward()\n",
        "        optimizer_classify.step()\n",
        "        pred = pred_label.data.max(1, keepdim=True)[1]\n",
        "        n_correct += pred.eq(classv_label.data.view_as(pred)).cpu().sum()\n",
        "        n_total += batch_size\n",
        "        latent_img_list.append(latent_img)\n",
        "\n",
        "        i += 1\n",
        "    \n",
        "    accu = n_correct * 1.0 / n_total\n",
        "    print ('epoch: %d, svhn train accuracy: %f' %(epoch, accu))\n",
        "\n",
        "    # latent_img_list = torch.cat(latent_img_list).cpu().detach().numpy() #data.cpu().numpy()\n",
        "    # print(latent_img_list.shape)\n",
        "    # X_embedded = TSNE(n_components=2).fit_transform(latent_img_list)\n",
        "\n",
        "    torch.save(my_net, '{0}/svhn_mnist_model_epoch_{1}.pth'.format(model_root, epoch))\n",
        "\n",
        "    rec_image(epoch)\n",
        "    test(epoch)\n",
        "\n",
        "print ('done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:330: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, svhn train accuracy: 0.534857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DRCN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Upsample. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 0, svhn test accuracy: 0.843750\n",
            "epoch: 0, mnist test accuracy: 0.674700\n",
            "epoch: 1, svhn train accuracy: 0.757907\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 1, svhn test accuracy: 0.859375\n",
            "epoch: 1, mnist test accuracy: 0.712500\n",
            "epoch: 2, svhn train accuracy: 0.801248\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 2, svhn test accuracy: 0.859375\n",
            "epoch: 2, mnist test accuracy: 0.727000\n",
            "epoch: 3, svhn train accuracy: 0.818297\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 3, svhn test accuracy: 0.812500\n",
            "epoch: 3, mnist test accuracy: 0.704600\n",
            "epoch: 4, svhn train accuracy: 0.834023\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 4, svhn test accuracy: 0.875000\n",
            "epoch: 4, mnist test accuracy: 0.719100\n",
            "epoch: 5, svhn train accuracy: 0.841176\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 5, svhn test accuracy: 0.859375\n",
            "epoch: 5, mnist test accuracy: 0.693700\n",
            "epoch: 6, svhn train accuracy: 0.846936\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 6, svhn test accuracy: 0.875000\n",
            "epoch: 6, mnist test accuracy: 0.682400\n",
            "epoch: 7, svhn train accuracy: 0.853802\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 7, svhn test accuracy: 0.859375\n",
            "epoch: 7, mnist test accuracy: 0.716600\n",
            "epoch: 8, svhn train accuracy: 0.855495\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 8, svhn test accuracy: 0.875000\n",
            "epoch: 8, mnist test accuracy: 0.735400\n",
            "epoch: 9, svhn train accuracy: 0.858949\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 9, svhn test accuracy: 0.859375\n",
            "epoch: 9, mnist test accuracy: 0.733600\n",
            "epoch: 10, svhn train accuracy: 0.861392\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 10, svhn test accuracy: 0.843750\n",
            "epoch: 10, mnist test accuracy: 0.721300\n",
            "epoch: 11, svhn train accuracy: 0.865119\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 11, svhn test accuracy: 0.875000\n",
            "epoch: 11, mnist test accuracy: 0.718100\n",
            "epoch: 12, svhn train accuracy: 0.867139\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 12, svhn test accuracy: 0.875000\n",
            "epoch: 12, mnist test accuracy: 0.738100\n",
            "epoch: 13, svhn train accuracy: 0.868600\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 13, svhn test accuracy: 0.890625\n",
            "epoch: 13, mnist test accuracy: 0.707200\n",
            "epoch: 14, svhn train accuracy: 0.870797\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 14, svhn test accuracy: 0.875000\n",
            "epoch: 14, mnist test accuracy: 0.666400\n",
            "epoch: 15, svhn train accuracy: 0.870988\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 15, svhn test accuracy: 0.843750\n",
            "epoch: 15, mnist test accuracy: 0.668900\n",
            "epoch: 16, svhn train accuracy: 0.872435\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 16, svhn test accuracy: 0.890625\n",
            "epoch: 16, mnist test accuracy: 0.698900\n",
            "epoch: 17, svhn train accuracy: 0.872026\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 17, svhn test accuracy: 0.875000\n",
            "epoch: 17, mnist test accuracy: 0.657200\n",
            "epoch: 18, svhn train accuracy: 0.874770\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 18, svhn test accuracy: 0.843750\n",
            "epoch: 18, mnist test accuracy: 0.711300\n",
            "epoch: 19, svhn train accuracy: 0.876585\n",
            "Using downloaded and verified file: /content/gdrive/My Drive/dataset/svhn/test_32x32.mat\n",
            "epoch: 19, svhn test accuracy: 0.859375\n",
            "epoch: 19, mnist test accuracy: 0.680300\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}